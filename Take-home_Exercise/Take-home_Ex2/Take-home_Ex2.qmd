---
title: "Take-home-Ex2:Applied Spatial Interaction Models: A case study of Singapore public bus commuter flows"
author: "Widya Tantiya Yutika"
date: "08 December 2023"
date-modified: "last-modified"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

## Overview

Urban mobility challenges encompass understanding the driving forces behind early morning commutes for city dwellers and evaluating the impact of removing public bus services along specific routes, presenting complex issues for transport operators and urban managers. Traditional commuter surveys, though effective, are costly and time-consuming. With the digitization of urban infrastructures, particularly public transportation, massive geospatial data sets are generated through technologies like GPS and SMART cards. However, the inability to efficiently utilize this data can hinder effective decision-making. This exercise aims to address two key issues: the lack of research on integrating diverse open data sources for policymaking and the insufficient exploration of geospatial data science for decision support. The objective is to conduct a case study showcasing the potential of geospatial data science in integrating publicly available data to build spatial interaction models, explaining factors influencing urban mobility patterns in public bus.

## **The Study Area and Data**

### Aspatial Data

-   Open Government Data

    -   *Passenger Volume by Origin Destination Bus Stops* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html).

    -   *School Directory and Information* from [Data.gov.sg](https://beta.data.gov.sg/).

-   Instructor-curated Datasets for Educational Purpose

    -   HDB: This data set is the geocoded version of *HDB Property Information* data from [Data.gov.sg](https://beta.data.gov.sg/). The data set is prepared using September 2021 data.

### Geospatial Data

-   Open Government Data

    -   *Bus Stop Location*, *Train Station* and *Train Station Exit Point from* [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html).

    -   *Master Plan 2019 Subzone Boundary* from [Data.gov.sg](https://beta.data.gov.sg/).

-   Instructor-curated Datasets for Educational Purpose

    -   *Business*, *entertn*, *F&B*, *FinServ*, *Leisure&Recreation* and *Retails* consisting locations of business establishments, entertainments, food and beverage outlets, financial centres, leisure and recreation centres, retail and services stores/outlets.

## **Setting the Analytical Tools**

Before I get started, I need to ensure that **sf**, **spdep**, **tmap**, **tidyverse,** and **knitr** packages of R are currently installed in my R.

-   *sf* : for importing and handling geospatial data in R,

-   *spdep* : for computing spatial weights, global and local spatial autocorrelation statistics, and

-   *tmap* : for preparing cartographic quality chropleth map

-   *tidyverse* : for wrangling attribute data in R ; [tidyverse](https://www.tidyverse.org/) has already included collection of packages such as readr, ggplot2, dplyr, tiblle, purr, etc.

-   knitr: for facilitating dynamic report generation in R Markdown documents.

-   sp:???

-   reshape2

-   stplanr

-   httr

The code chunk below is used to ensure that the necessary R packages have been installed , if it is yet to be installed, it will then be installed and ready to be used in the R environment.

```{r}
#| code-fold: true 
#| code-summary: "Show the code" 
pacman::p_load(sf, spdep, tmap, tidyverse, knitr, sp, reshape2, stplanr, httr)
```

## **Preparing the Flow Data**

### **Importing OD Csv File into R Environment**

Next, I will import *Passenger Volume by Origin Destination Bus Stops* data set: *origin_destination_bus_202310.csv* into R by using [*`st_read()`*](#0){style="font-size: 11pt;"} of **readr** package. The output is R dataframe class.

```{r}
#| code-fold: true  
#| code-summary: "Show the code"  
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

The code chunk below uses [*`glimpse()`*](https://www.rdocumentation.org/packages/dplyr/versions/1.0.10/topics/glimpse) of **dplyr** package to display the odbus tibble data tables.

```{r}
#| code-fold: true  
#| code-summary: "Show the code"
glimpse(odbus)
```

From the glimpse() check above, it is shown that the ORIGIN_PT_CODE and DESTINATION_PT_CODE are in character type. Both of them need to be converted to factor type to work with categorical variables so that I can use them to georeference with bus stop location data.

```{r}
#| code-fold: true  
#| #| #| code-summary: "Show the code"  
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

I will also change the data type of TIME_PER_HOUR and TOTAL_TRIPS from \<dbl\> to \<int\> because it both of these fields should be represented as whole numbers.

```{r}
#| code-fold: true  
#| code-summary: "Show the code"  
odbus$TIME_PER_HOUR <- as.integer(odbus$TIME_PER_HOUR)
odbus$TOTAL_TRIPS <- as.integer(odbus$TOTAL_TRIPS) 
```

Next, I will confirm the data type for ORIGIN_PT_CODE and DESTINATION_PT_CODE have changed to factor using glimpse().

```{r}
#| code-fold: true  
#| code-summary: "Show the code"  
glimpse(odbus)
```

### Extracting the Study Data

For the purpose of this take-home exercise, I will extract commuting flows on weekday and between 5 and 8 pm.

```{r}
#| code-fold: true   
#| #| code-summary: "Show the code"
odbus17_20 <- odbus %>%      
  filter(DAY_TYPE == "WEEKDAY") %>%      
  filter(TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE,DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

## Working with Geospatial Data

### **Importing Shapefile into R Environment**

-   Bus Stop Location

The code chunk below uses [*`st_read()`*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import BusStop shapefile into R. The imported shapefile will be **simple features** Object of **sf**. Then, I use [*`st_transform`*](https://r-spatial.github.io/sf/reference/st_transform.html) of **sp** package to convert coordinates to EPSG code of 3414 for SVY21.

```{r}
#| code-fold: true 
#| code-summary: "Show the code" 
busstop <- st_read(dsn = "data/geospatial", layer = "BusStop") %>%
  st_transform(crs = 3414)
```

-   *Master Plan 2019 Subzone Boundary*

The code chunk below uses [*`st_read()`*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import MPSZ-19 shapefile into R. The imported shapefile will be **simple features** Object of **sf**. Then, I use [*`st_transform`*](https://r-spatial.github.io/sf/reference/st_transform.html) of **sp** package to convert coordinates to EPSG code of 3414 for SVY21.

```{r}
#| code-fold: true 
#| code-summary: "Show the code" 
mpsz <- st_read(dsn = "data/geospatial", layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
```

## Creating honeycomb_grid

Honeycomb grid are preferred to replace coarse and irregular Master Plan 2019 Sub-zone GIS data set of URA because hexagon reduce sampling bias due to its grid shape of low perimeter to are ratio and its ability to form evenly spaced grid. Honeycomb grids are well-suited for approximating circular areas, making them suitable for mapping Singapore edges with irregular shape.

The code chunk below uses [*`st_make_grid`*](https://r-spatial.github.io/sf/reference/st_make_grid.html) of **sf** package to create a hexagonal or honeycomb grid with a 375m (perpendicular distance between the center of hexagon and its edges) to represent the [traffic analysis zone (TAZ)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf). According the the R documentation, the cellsize is the distance between opposite edges, which is 2 times the perpendicular distance between the center of hexagon and its edges. Thus, for the purpose of this exercise, I will use the cellsize of 750m and indicate the square=FALSE for hexagonal grid. After doing do, I will create a grid_id for each hexagonal grid.

```{r}
#| code-fold: true  
#| code-summary: "Show the code"  
area_honeycomb_grid = st_make_grid(busstop, c(750, 750), what = "polygons", square = FALSE)      
# To sf and add grid ID    
honeycomb_grid_sf = st_sf(area_honeycomb_grid) %>%
  # add grid ID            
  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))
```

## Data Wrangling for Geospatial Data

#### Combining Busstop and honeycomb_grid_sf

```{r}
#busstop_mpsz <- st_intersection(busstop, mpsz)
```

```{r}
#| code-fold: true  
#| code-summary: "Show the code"  
#area_honeycomb_grid1 = st_make_grid(busstop_mpsz, c(750, 750), what = "polygons", square = FALSE)      
# To sf and add grid ID    
#honeycomb_grid_sf1 = st_sf(area_honeycomb_grid1) %>%
  # add grid ID            
  #mutate(grid_id = 1:length(lengths(area_honeycomb_grid1)))
```

The code chunk below populates the honeycomb id (i.e. grid_id) of honeycomb_grid_sf data frame into busstop sf data frame.

```{r}
#busstop_honeycomb <- st_intersection(busstop_mpsz, honeycomb_grid_sf) %>%
#  select(BUS_STOP_N, grid_id) %>%
#  st_drop_geometry()
```

Notes: There are 5 bus stops outside Singapore boundary which are excluded.

```{r}
busstop_honeycomb <- st_intersection(busstop, honeycomb_grid_sf) %>%
  select(BUS_STOP_N, grid_id) %>%
  st_drop_geometry()
```

### Combining Aspatial and Geospatial Data

The code chunk below append the planning subzone code from busstop_mpsz data frame onto odbus17_20 data frame.

```{r}
od_data <- left_join(odbus17_20 , busstop_honeycomb,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = grid_id,
         DESTIN_BS = DESTINATION_PT_CODE)
```

#### Checking Duplicate Records

The code chunk below is used to check for duplicated records on od_data.

```{r}
#| code-fold: true 
#| #| code-summary: "Show the code" 
duplicate <- od_data %>%   
  group_by_all() %>%   
  filter(n()>1) %>%   
  ungroup()
```

The above code chunk shows that there are some duplicates record found. The code chunk below will be used to retain the unique records.

```{r}
od_data <- unique(od_data)
```

Next, we will update od_data data frame with the honeycomb grid_id.

```{r}
od_data <- left_join(od_data , busstop_honeycomb,
            by = c("DESTIN_BS" = "BUS_STOP_N")) 
```

```{r}
od_data <- od_data %>%
  rename(DESTIN_SZ = grid_id) %>%
  drop_na() %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>%
  summarise(AFTERNOON_PEAK = sum(TRIPS)) %>%
  filter(!is.na(AFTERNOON_PEAK))
```

```{r}
summary(od_data$AFTERNOON_PEAK)
```

I will save the output into an rds file format.

```{r}
write_rds(od_data, "data/rds/od_data.rds")
```

```{r}
od_data <- read_rds("data/rds/od_data.rds")
```

## **Visualising Spatial Interaction**

In this section, you will learn how to prepare a desire line by using **stplanr** package.

### **Removing intra-zonal flows**

We will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.

```{r}
od_data1 <- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]
```

### **Creating desire lines**

In this code chunk below, `od2line()` of **stplanr** package is used to create the desire lines.

```{r}
flowLine <- od2line(flow = od_data1, zones = honeycomb_grid_sf, zone_code = "grid_id")

```

### **Visualising the desire lines**

```{r}
honeycomb_grid_with_busstop <- honeycomb_grid_sf[honeycomb_grid_sf$grid_id %in% c(unique(flowLine$ORIGIN_SZ), unique(flowLine$DESTIN_SZ)), ] 
```

```{r}

```

To visualise the resulting desire lines, the code chunk below is used.

```{r}
#tmap_options(check.and.fix = TRUE)
tmap_mode("view")
#tm_shape(mpsz)+
  #tm_polygons()+
tm_shape(honeycomb_grid_with_busstop) +   
  tm_polygons(col = "lightblue") + 
  flowLine %>%
  filter(AFTERNOON_PEAK >= 5000) %>%
  tm_shape() +   
  tm_lines(lwd = "AFTERNOON_PEAK",            
           style = "quantile",            
           scale = c(0.1, 1, 3, 5, 7, 10),            
           n = 6,            
           alpha = 0.3)+
  tm_view(set.zoom.limits =c(11,14))

tmap_mode("plot")
```

The blue hexagonal grid refers to the grid with busstop and the plot above only show the flowline with more or equal than 5000trips.

## **Computing Distance Matrix**

### **Converting from sf data.table to SpatialPolygonsDataFrame**

In view of this, sp method is used in the code chunks below.

First [`as.Spatial()`](https://r-spatial.github.io/sf/reference/coerce-methods.html) will be used to convert *mpsz* from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.

```{r}
honeycomb_grid_with_busstop_sp <- as(honeycomb_grid_with_busstop, "Spatial") 
honeycomb_grid_with_busstop_sp
```

### **Computing the distance matrix**

```{r}
dist <- spDists(honeycomb_grid_with_busstop_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

### **Pivoting distance value by grid_id**

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

### **Updating intra-zonal distances**

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Next, a constant distance value of 375m is added into intra-zones distance. (the distance within the hexagonal grid).

```{r}
distPair$dist <- ifelse(distPair$dist == 0, 375, distPair$dist)
```

```{r}
distPair %>%
  summary()
```

## **Preparing flow data**

```{r}
flow_data1 <- od_data1 %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "Var1",
                    "DESTIN_SZ" = "Var2"))
```

## School Dataset

### **Geocoding using SLA API**

```{r}
#|eval: false
url <- "https://www.onemap.gov.sg/api/common/elastic/search"

csv <- read_csv("data/aspatial/Generalinformationofschools.csv")
postcodes <- csv$'postal_code'

found <- data.frame()
not_found <- data.frame()

for (postcode in postcodes){
  query <- list('searchVal'=postcode,'returnGeom'='Y','getAddrDetails'='Y','pageNum'='1')
  res<-GET(url, query=query)
  
  if((content(res)$found)!=0){
    found <-rbind(found, data.frame(content(res))[4:13])
  } else{
    not_found = data.frame(postcode)
  }
}
```

```{r}
#merged = merge(csv, found, by.x='postal_code', by.y='results.POSTAL', all=TRUE)
#write.csv (merged, file='data/aspatial/schools.csv')
#write.csv (not_found, file ='data/aspatial/not_found.csv')
```

### **Importing and tidying schools data**

```{r}
schools <- read_csv("data/aspatial/schools.csv") %>%
  rename(latitude='results.LATITUDE', longitude='results.LONGITUDE')%>%
  select(postal_code, school_name, latitude,longitude)
```

### **Converting an aspatial data into sf tibble data.frame**

```{r}
schools_sf <- st_as_sf(schools, 
                       coords=c('longitude', 'latitude'),
                       crs=4326) %>%
  st_transform(crs=3414)
```

```{r}
honeycomb_grid_sf$'SCHOOL_COUNT' <- lengths(st_intersects(honeycomb_grid_sf, schools_sf))
```

```{r}
summary(honeycomb_grid_sf$SCHOOL_COUNT)
```

```{r}
tmap_mode("view")
tm_shape(honeycomb_grid_sf %>% filter(SCHOOL_COUNT>0)) +   
  tm_polygons(col = "lightblue") + 
  tm_text("SCHOOL_COUNT", size=0.8) +
  tm_view(set.zoom.limits =c(11,14))


tmap_mode("plot")
```

## HDB Dataset

```{r}
hdb <- read_csv("data/aspatial/hdb.csv")
```

### **Converting an aspatial data into sf tibble data.frame**

```{r}
hdb_sf <- st_as_sf(hdb,                         
                       coords=c('lng', 'lat'),                        
                       crs=4326) %>%   
  st_transform(crs=3414)
```

```{r}
hdb_count <- st_intersection(honeycomb_grid_sf, hdb_sf) %>%
  group_by(grid_id) %>%
  summarise(HDB_DWELLING_UNIT=sum(total_dwelling_units)) %>%
  st_drop_geometry()
```

```{r}
honeycomb_grid_sf = left_join(honeycomb_grid_sf, hdb_count)
```

```{r}
summary(honeycomb_grid_sf$HDB_DWELLING_UNIT)
```

```{r}
#tmap_mode("view")
tmap_mode("plot")
tmap_options(check.and.fix = TRUE) 
tm_shape(mpsz)+
  tm_polygons()+
tm_shape(honeycomb_grid_sf %>% filter(HDB_DWELLING_UNIT>0)) +   
  tm_polygons(col="HDB_DWELLING_UNIT", alpha=0.6, breaks=c(1,800,1600,2400,3200,4800,8000)) + 
  #tm_text("HDB_DWELLING_UNIT", size=0.8) +
  tm_view(set.zoom.limits =c(11,14))


tmap_mode("plot")
```

## Business Layer

```{r}
business_sf <- st_read(dsn="data/geospatial", layer="Business")
```

```{r}
honeycomb_grid_sf$'BUSINESS_COUNT' <- lengths(st_intersects(honeycomb_grid_sf, business_sf))
```

```{r}
summary(honeycomb_grid_sf$'BUSINESS_COUNT')
```

```{r}
#tmap_mode("view")
tmap_mode("plot")
tmap_options(check.and.fix = TRUE) 
tm_shape(mpsz)+
  tm_polygons()+
tm_shape(honeycomb_grid_sf %>% filter(BUSINESS_COUNT>0)) +   
  tm_polygons(col="BUSINESS_COUNT", alpha=0.6, breaks=c(1,5,10,20,30,97)) + 
  #tm_text("BUSINESS_COUNT", size=0.8) +
  #tm_view(set.zoom.limits =c(11,14))
tmap_mode("plot")
```

## Entertainment Layer

```{r}
entertainment_sf <- st_read(dsn="data/geospatial", layer="entertn")
```

```{r}
honeycomb_grid_sf$'ENTERTAINMENT_COUNT' <- lengths(st_intersects(honeycomb_grid_sf, entertainment_sf))
```

```{r}
summary(honeycomb_grid_sf$'ENTERTAINMENT_COUNT')
```

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE) 
tm_shape(mpsz)+
  tm_polygons()+
tm_shape(honeycomb_grid_sf %>% 
           filter(ENTERTAINMENT_COUNT>0)) +      
  tm_polygons(col="ENTERTAINMENT_COUNT", alpha=0.6, breaks=c(1,4,7,9)) +    
  #tm_view(set.zoom.limits =c(11,14))  
tmap_mode("plot")
```

## F&B

## Financial Service

## Leisure and Recreation

## Retails

## Train Station

```{r}
train_station_sf <- st_read(dsn="data/geospatial", layer="RapidTransitSystemStation") %>%
  st_transform(crs = 3414)
```

```{r}
st_crs(train_station_sf)
```

### Exclude Depot and Facility Center from the dataset

```{r}
filtered_train_station_sf <- train_station_sf %>%
  filter(grepl("STATION", STN_NAM_DE, ignore.case = TRUE))
```

```{r}
honeycomb_grid_sf$'TRAIN_STATION_COUNT' <- lengths(st_intersects(honeycomb_grid_sf, filtered_train_station_sf))
```

```{r}
summary(honeycomb_grid_sf$'TRAIN_STATION_COUNT')
```

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE) 
tm_shape(mpsz)+
  tm_polygons()+
tm_shape(honeycomb_grid_sf %>% 
           filter(TRAIN_STATION_COUNT>0)) +      
  tm_polygons(col="TRAIN_STATION_COUNT", alpha=0.6, breaks=c(1,3,5,6)) +    
  #tm_view(set.zoom.limits =c(11,14))  
tmap_mode("plot")
```

## MRT Station EXIT

```{r}
MRT_exit_sf <- st_read(dsn="data/geospatial", layer="Train_Station_Exit_Layer") %>%
  st_transform(crs = 3414)
```

```{r}
honeycomb_grid_sf$'MRT_EXIT_COUNT' <- lengths(st_intersects(honeycomb_grid_sf, MRT_exit_sf))
```

```{r}
summary(honeycomb_grid_sf$'MRT_EXIT_COUNT')
```

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE) 
tm_shape(mpsz)+
  tm_polygons()+
tm_shape(honeycomb_grid_sf %>% 
           filter(MRT_EXIT_COUNT>0)) +      
  tm_polygons(col="MRT_EXIT_COUNT", alpha=0.6, breaks=c(1,4,7,10,13)) +    
  #tm_view(set.zoom.limits =c(11,14))  
tmap_mode("plot")
```

### Flow_Data_Tidy
