---
title: "Take-home_Ex1: Public Bus Passengers in Singapore"
author: "Widya Tantiya Yutika"
date: "29 November 2023"
date-modified: "last-modified"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

## Overview

The increasing digitization of urban infrastructures, including buses, taxis, mass rapid transit, public utilities and roads, has generated vast datasets capturing movement patterns over space and time. This data, facilitated by technologies such as GPS and RFID, offers valuable insights into human mobility within cities. Smart cards and GPS devices on public buses, for instance, have enabled the collection of routes and ridership data, providing a rich source for understanding urban movement.

Despite the wealth of data collected, its utilization often remains limited to basic tracking and mapping using Geographic Information System (GIS) applications. This limitation is attributed to the inadequacy of conventional GIS functions in effectively analyzing and modeling spatial and spatio-temporal data.

The objectives of this study are centered around employing Exploratory Spatial Data Analysis (ESDA) techniques, specifically Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA), to unveil the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

## **The Study Area and Data**

### Aspatial Data

The aspatial data used in this take-home exercise is extracted from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) (*Passenger Volume by Origin Destination Bus Stops*) for the month of October 2023.

### Geospatial Data

The geospatial data used in this take-home exercise are as follows.

-   *Bus Stop Location* from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html), which provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.

-   *hexagon*, a [hexagon](https://desktop.arcgis.com/en/arcmap/latest/tools/spatial-statistics-toolbox/h-whyhexagons.htm) layer of 250m perpendicular distance between the centre of the hexagon and its edges is used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA.

## **Setting the Analytical Tools**

Before I get started, I need to ensure that **sf**, **spdep**, **tmap**, **tidyverse,** and **knitr** packages of R are currently installed in my R.

-   *sf* : for importing and handling geospatial data in R,

-   *spdep* : for computing spatial weights, global and local spatial autocorrelation statistics, and

-   *tmap* : for preparing cartographic quality chropleth map

-   *tidyverse* : for wrangling attribute data in R ; [tidyverse](https://www.tidyverse.org/) has already included collection of packages such as readr, ggplot2, dplyr, tiblle, purr, etc.

-   knitr: for facilitating dynamic report generation in R Markdown documents.

The code chunk below is used to ensure that the necessary R packages have been installed , if its iyet to be installed, it will then be installed and ready to be used in the R environment.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
```

## **Getting the Data into R Environment**

### **Importing Shapefile into R Environment**

The code chunk below uses [*`st_read()`*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import BusStop shapefile into R. The imported shapefile will be **simple features** Object of **sf**.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop <- st_read(dsn = "data/geospatial", layer = "BusStop")
```

The code chunk below uses [*`st_geometry()`*](https://www.rdocumentation.org/packages/sf/versions/1.0-14/topics/st_geometry) of **sf** package to display basic information of feature class.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
st_geometry(busstop)
```

The code chunk below uses [*`glimpse()`*](https://www.rdocumentation.org/packages/dplyr/versions/1.0.10/topics/glimpse) of **dplyr** package to display the data type of each fields.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(busstop)
```

Next, I will plot the geospatial data using the code chunk below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
plot(busstop)
```

From the glimpse() check above, it is shown that the BUS_STOP_N is in character type. It needs to be converted to factor type to work with categorical variables so that I can use them to georeference with bus stop location data.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop$BUS_STOP_N <- as.factor(busstop$BUS_STOP_N)
```

Next, I will confirm the data type for BUS_STOP_N has changed to data type of "factor" using glimpse().

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(busstop)
```

### **Importing Csv File into R Environment**

Next, I will import *origin_destination_bus_202310.csv* into R by using [*`st_read()`*](https://r-spatial.github.io/sf/reference/st_read.html) of **readr** package. The output is R dataframe class.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

The code chunk below uses [*`glimpse()`*](https://www.rdocumentation.org/packages/dplyr/versions/1.0.10/topics/glimpse) of **dplyr** package to display the odbus tibble data tables.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(odbus)
```

From the glimpse() check above, it is shown that the ORIGIN_PT_CODE and DESTINATION_PT_CODE are in character type. Both of them need to be converted to factor type to work with categorical variables so that I can use them to georeference with bus stop location data.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

I will also change the data type of TIME_PER_HOUR and TOTAL_TRIPS from \<dbl\> to \<int\> because it both of these fields should be represented as whole numbers.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus$TIME_PER_HOUR <- as.integer(odbus$TIME_PER_HOUR)
odbus$TOTAL_TRIPS <- as.integer(odbus$TOTAL_TRIPS) 
```

Next, I will confirm the data type for ORIGIN_PT_CODE and DESTINATION_PT_CODE have changed to factor using glimpse().

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(odbus)
```

## Data Wrangling

### Checking the Reference Coordinate System of Geospatial Data

Common issue in importing geospatial data into R is that the coordinate system of the source data was either missing (due to missing .proj for ESRI shapefile, etc.) or wrongly assigned.

The code chunk below uses [*`st_crs()`*](https://www.rdocumentation.org/packages/sf/versions/0.2-8/topics/st_crs) of **sf** package to retrieve the coordinate reference system of busstop.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
st_crs(busstop)
```

Both busstop is projected in svy21 as shown from the second line, but at the last line, it is mentioned that the EPSG is 9001. This is wrongly assigned because the correct EPSG code for svy21 is [3414](https://epsg.io/3414).

### Transforming the Projection

Next, I will transform busstop from geographic coordinate system to projected coordinated system as my analysis will measure distance or/and area.

The code chunk below uses [*`st_transform`*](https://r-spatial.github.io/sf/reference/st_transform.html) of **sp** package to convert coordinates to EPSG code of 3414.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop3414 <- st_transform(busstop, 3414)
```

Next, I will check the coordinate system after transformation with the code chunk below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
st_crs(busstop3414)
```

As noticed from the above, the Projected CRS is now SVY21 / Singapore TM and the last line has changed to EPSG 3414.

### Checking Duplicated Records

The code chunk below is used to check for duplicated records on odbus.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
duplicate <- odbus %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

The above code chunk shows that there is no duplicate record found.

### Remove Unnecessary Fields

First, I check the YEAR_MONTH and PT_TYPE unique values by using the *`table()`* to create a frequency table of each categorical representation.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
YEAR_MONTH_counts <- table(odbus$YEAR_MONTH)
print(YEAR_MONTH_counts)

DAY_TYPE_counts <- table(odbus$DAY_TYPE)
print(DAY_TYPE_counts)

PT_TYPE_counts <- table(odbus$PT_TYPE)
print(PT_TYPE_counts)
```

From the results above, I will exclude YEAR_MONTH and PT_TYPE as they only have single categorical representation using the code chunk below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus <- odbus[, !(names(odbus) %in% c("YEAR_MONTH", "PT_TYPE"))]
```

I will then use glimpse() to ensure the process is done correctly.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(odbus)
```

## Creating honeycomb_grid[1](#References)

Honeycomb grid are preferred to replace coarse and irregular Master Plan 2019 Sub-zone GIS data set of URA because hexagon reduce sampling bias due to its grid shape of low perimeter to are ratio and its ability to form evenly spaced grid. Honeycomb grids are well-suited for approximating circular areas, making them suitable for mapping Singapore edges with is irregular shape.

The code chunk below uses [*`st_make_grid`*](https://r-spatial.github.io/sf/reference/st_make_grid.html) of **sf** package to create a hexagonal or honeycomb grid with a 250m (perpendicular distance between the center of hexagon and its edges). According the the R documentation, the cellsize is the distance between opposite edges, which is 2 times the perpendicular distance between the center of hexagon and its edges. Thus, for the purpose of this exercise, I will use the cellsize of 500m and indicate the square=FALSE for hexagonal grid. After doing do, I will create a grid_id for each hexagonal grid.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
area_honeycomb_grid = st_make_grid(busstop3414, c(500, 500), what = "polygons", square = FALSE)    
# To sf and add grid ID  
honeycomb_grid_sf = st_sf(area_honeycomb_grid) %>%    
  # add grid ID      
  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))
```

## Extracting the study data

In this exercise, I will extract the commuting flows during peak hours as follows.

|                              | Bus tap on time |
|------------------------------|-----------------|
| Weekday morning peak         | 6am to 9am      |
| Weekday afternoon peak       | 5pm to 8pm      |
| Weekend/holiday morning peak | 11am to 2pm     |
| Weekend/holiday evening peak | 4pm to 7pm      |

### Weekday Morning Peak

The code chunk below will be used to extract the weekday morning peak (Weekday: 6-9am) and calculate the passenger trips in each origin bus stop by using the *`group_by()`* from **dplyr** package and aggregate the values using *`summarise()`* and sum up the "Total_Trips". The *`mutate()`* in the code below is to ensure that after the group_by, the ORIGIN_PT_CODE remains in the factor data type.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus_weekday_6_9 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 &
           TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))%>%
  mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE))
```

I will repeat the processes above for the other peak hours as shown below.

### Weekday Afternoon Peak

The code chunk below will be used to extract the weekday afternoon peak (Weekday: 5-8pm) and calculate the passenger trips in each origin bus stop.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus_weekday_17_20 <- odbus %>%   
  filter(DAY_TYPE == "WEEKDAY") %>%   
  filter(TIME_PER_HOUR >= 17 &            
           TIME_PER_HOUR <= 20) %>%   
  group_by(ORIGIN_PT_CODE) %>%   
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE))
```

### Weekends/Holiday Morning Peak

The code chunk below will be used to extract the weekend/holiday morning peak (Weekend/holiday: 11am-2pm) and calculate the passenger trips in each origin bus stop.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus_weekend_11_14 <- odbus %>% 
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%   
  filter(TIME_PER_HOUR >= 11 &            
           TIME_PER_HOUR <= 14) %>%   
  group_by(ORIGIN_PT_CODE) %>%   
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE))
```

### Weekends/Holiday Evening Peak

The code chunk below will be used to extract the weekend/holiday evening peak (Weekend/holiday: 4-7pm) and calculate the total trips in each origin and destination pair.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus_weekend_16_19 <- odbus %>%   
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%   
  filter(TIME_PER_HOUR >= 16 &            
           TIME_PER_HOUR <= 19) %>%   
  group_by(ORIGIN_PT_CODE) %>%   
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE))
```

## Further Data Wrangling for Weekday Morning Peak Hour: A Step-by-Step Guide

This section provides a comprehensive step-by step walkthrough to calculate the number of trips within each hexagonal grid during Weekday Morning Peak Hour with a subsequent plan to replicate the same process for Weekday Afternoon Peak Hour, Weekends/Holiday Morning Peak, and Weekends/Holiday Evening Peak in the subsequent section

### Performing Relational Join

The code chunk below will be used to join the busstop3414 SpatialPolygonsDataframe and odbus_weekday_6_9_data by BUS_STOP_N for busstop3414 and BUS_STOP_ID for original_destination_bus. This is performed by using `left_join()` of **dplyr** package. In this take-home exercise, I will focus on passenger trips generated by origin bus stop, I will remove the rows with bus stops solely serve as destinations which are indicated by NA values on the corresponding "Total_Trips" using the *`filter()`* from **dplyr** package.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_busstop_wdmp <- left_join(busstop3414, odbus_weekday_6_9, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE")) %>%
  filter(!is.na(TRIPS))
```

### Spatial Join with Hexagonal Honeycomb Grid and Calculating Total Trips in a Hexagonal Grid

The code chunk below will be used to join the total_trips_per_busstop and honeycomb grid spatially using *`st_join()`* from **sf** package and remove the hexagon grid without any bus stop which is indicated by NA value on the "BUS_STOP_N". Next, I will calculate the total trips in a hexagonal grid using the *`group_by()`* from **dplyr** package.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wdmp <- st_join(honeycomb_grid_sf,total_trips_per_busstop_wdmp) %>%
  filter(!is.na(BUS_STOP_N))%>%
  group_by(grid_id) %>%
  summarise(total_trips = sum(TRIPS))
```

### Replicating the Steps for Other Peak Hours

#### Weekday Afternoon Peak

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_busstop_wdap <- left_join(busstop3414, odbus_weekday_17_20, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))%>%
  filter(!is.na(TRIPS))

total_trips_per_grid_wdap <- st_join(honeycomb_grid_sf,total_trips_per_busstop_wdap) %>%
  filter(!is.na(BUS_STOP_N))%>%
  group_by(grid_id) %>%
  summarise(total_trips = sum(TRIPS))
```

#### Weekends/Holiday Morning Peak

```{r}
#| code-fold: true
#| code-summary: "Show the code"

total_trips_per_busstop_wemp <- left_join(busstop3414, odbus_weekend_11_14, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))%>%
  filter(!is.na(TRIPS))

total_trips_per_grid_wemp <- st_join(honeycomb_grid_sf,total_trips_per_busstop_wemp) %>%
  filter(!is.na(BUS_STOP_N))%>%
  group_by(grid_id) %>%
  summarise(total_trips = sum(TRIPS))
```

#### Weekends/Holiday Evening Peak

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_busstop_weep <- left_join(busstop3414, odbus_weekend_16_19, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))%>%
  filter(!is.na(TRIPS))

total_trips_per_grid_weep <- st_join(honeycomb_grid_sf,total_trips_per_busstop_weep) %>%
  filter(!is.na(BUS_STOP_N))%>%
  group_by(grid_id) %>%
  summarise(total_trips = sum(TRIPS))
```

## Geovisualisation and Analysis

After the data preparation, I will first plot the distribution of passenger trips using *`ggplot()`* of **tidyverse** package. To consolidate these distributions into a single plot, it is necessary to introduce grouping variable to each dataframe. Within this unified plot, key summary statistics including Q1, median, Q3, and mean highligthed by a red circle will be presented. This approach aims to provide a comprehensive comparison of passenger trip characteristics across various peak hour groups.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
# Add a grouping variable to each dataframe
total_trips_per_grid_wdmp$Peak_Hour_Group <- "wdmp"
total_trips_per_grid_wdap$Peak_Hour_Group <- "wdap"
total_trips_per_grid_wemp$Peak_Hour_Group <- "wemp"
total_trips_per_grid_weep$Peak_Hour_Group <- "weep"

# Combine dataframes into a single dataframe
combined_peak_hour <- rbind(total_trips_per_grid_wdmp, total_trips_per_grid_wdap, total_trips_per_grid_wemp, total_trips_per_grid_weep) %>%
  filter(!is.na(total_trips))

# Create a box plot using ggplot
ggplot(combined_peak_hour, aes(x = Peak_Hour_Group, y = total_trips)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape = 18, size = 3, color = "red")+
  stat_boxplot(geom = 'errorbar', width = 0.5, color = 'blue', size = 1)+
  stat_summary(
    geom = 'text',
    fun.min = function(x) quantile(x, 0.25),
    fun = median,
    fun.max = function(x) quantile(x, 0.75),
    aes(label = sprintf("Q3: %.2f\nMedian: %.2f\nQ1: %.2f", ..ymax.., ..y.., ..ymin..)),
    vjust = -5,
    hjust= -0.08,
    position = position_dodge(width = 0.75),
    size = 3
  ) +
  stat_summary(geom = 'text', fun = mean, aes(label = sprintf("Mean: %.2f", ..y..)), vjust = -3, hjust=-0.08 ,  position = position_dodge(width = 0.9), color = 'red', size =3)+
  
  labs(title = "Boxplot for Total Trips in each Peak Hour Group", x="Peak Hour Group",y = "Passenger Trips") +
  theme_minimal()

```

The box plot analysis above reveal the patterns in Singapore's bus passenger trips. Notably, the mean passenger trips during weekdays significantly surpass those on weekends and holidays, suggesting higher demand for bus services during typical workdays. This aligns with a common observation that commuting is more crowded on workdays, reflecting the daily hustle and bustle of the workforce.

Furthermore, the observation that the mean of all peak hour groups exceeds their respective medians indicates a right-skewed distribution. This skewness implies that on average, there are more instances of relatively small number of passenger trips during peak hour with occasional instances of significantly higher demand. This distribution pattern underscores the challenges faced by commuters during peak hours, where a substantial portion of bus rides may experience higher congestion.

Some hexagonal grid has a total of more than 400,000 passenger trips highlighting that specific areas with exceptionally high demand during the weekdays. These areas are likely represent key commuting regions with concentrated commercial and residential activities and are possibly areas that are not easily accessible by MRT. To gain clearer insights on the concentrations of high passenger trips I will leverage **tmap** package.

### Weekday Morning Peak

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("view")

tm_shape(total_trips_per_grid_wdmp) +
  tm_fill(
    col = "total_trips",
    palette = c("#C5FFF8", "#FF4B91"),
    style = "cont",
    title = "Number of Trips",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c("grid_id","total_trips"),
    popup.format = list(
      grid_id = list(format = "f", digits = 0),
      total_trips = list(format = "f", digits = 0))
  ) +
  tm_borders(col = "grey40", lwd = 0.7)
tmap_mode("plot")
```

It has been observed that certain bus stops are located outside the boundaries of Singapore, particularly in Johor.The influx of weekday morning peak passenger trips from Johor are qhigh surpassing 100,000 for October 2023. This significant amount shows the cross border commuting activity between Johor and Singapore suggesting a preference among some individuals to reside in Johor may be due to cost consideration while working in Singapore.

The Central Business District (CBD) area displays a comparatively lower passenger trips generated by origin bus stop. This is attributed to the absence of major bus interchanges within the CBD, suggesting that commuters in this central business hub may rely on alternative modes of transportation, such as the Mass Rapid Transit (MRT) system. In addition, it is worth noting that lower passenger trips may also be influences by the fact that bus routes typically do not commence within CBD area, even though the bus routes pass through CBD.

Areas that are exhibiting a high concentration during weekday morning peak are associated with prominent bus interchanges such as Woodlands and Boon Lay with more than 300,000 passenger trips within a single month on weekdays. Additionally, other bus interchanges including Bishan, Ang Mo Kio, Toa Payoh, Clementi, Punggol, Tampines, and Bedok also shows high passenger trips.

### Weekday Afternoon Peak

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")

tm_shape(total_trips_per_grid_wdap) +
  tm_fill(
    col = "total_trips",
    palette = c("#C5FFF8", "#FF4B91"),
    style = "cont",
    title = "Number of Trips",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c("grid_id","total_trips"),
    popup.format = list(
      grid_id = list(format = "f", digits = 0),
      total_trips = list(format = "f", digits = 0))
  ) +
  tm_borders(col = "grey40", lwd = 0.7)
tmap_mode("plot")
```

During the weekday afternoon peak, Woodlands and Boon Lay continue to exhibit an impressive volume of passenger trips exceeding 400,000 as compared to the patterns observed during morning peak. In addition, there are additional areas such as Ang Mo Kio, Tampines, and Bedok which emerge as significant contributors to the passenger trips during the later peak period.

Typically the passengers volume during weekday afternoon are higher than weekday morning with Boon Lay with the highest contributor of more than 500,000 passenger trips. Boon Lay serves as a transportation hub for workers, residents and students from NTU. Moreover, the areas near Boon Lay are currently not accessible through MRT as the development of MRT is still in progress.

### Weekends/Holiday Morning Peak

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
tm_shape(total_trips_per_grid_wemp) +
  tm_fill(
    col = "total_trips",
    palette = c("#C5FFF8", "#FF4B91"),
    style = "cont",
    title = "Number of Trips",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c("grid_id","total_trips"),
    popup.format = list(
      grid_id = list(format = "f", digits = 0),
      total_trips = list(format = "f", digits = 0))
  ) +
  tm_borders(col = "grey40", lwd = 0.7)
tmap_mode("plot")
```

Given that weekends consist of only two days, the passenger trip numbers exhibit lower in total numbers but comparable to those recorded during five weekdays, following a similar pattern. Notably, major bus interchanges, such as Woodlands, Boon Lay, Bedok and Tampines continue to play a pivotal role contributing significantly to the overall passenger trips during both weekdays and weekends.

During weekend and holidays, the morning peak hour (11am to 2pm) is later as compared to weekday morning (6 to 9am). This temporal shift can be attributed to social dynamic where individuals engaging in lunchtime activity with family and friends during weekends. This distinctive pattern underscores the influence of social interactions on commuter behaviors during non-working days.

### Weekends/Holiday Evening Peak

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
tm_shape(total_trips_per_grid_weep) +
  tm_fill(
    col = "total_trips",
    palette = c("#C5FFF8", "#FF4B91"),
    style = "cont",
    title = "Number of Trips",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c("grid_id","total_trips"),
    popup.format = list(
      grid_id = list(format = "f", digits = 0),
      total_trips = list(format = "f", digits = 0))
  ) +
  tm_borders(col = "grey40", lwd = 0.7)
tmap_mode("plot")
```

Similar with the other peak hours, the passenger trips are mostly contributed by major bus interchange as the origin.

Typically , the afternoon/evening peak hours witnesses a higher volume of passenger trips both on weekdays and weekend as compared to morning peak hours. This preference may be due to individuals opting for MRT during hours as it provide punctual mode of transportation as compared to bus which might be affected by congestion and could potentially lead to delays in reaching to work/schools/leisure activities.

During weekend and holidays, the evening peak hour (4 to 7pm) is slightly earlier as compared to weekday morning afternoon (5 to 8pm). This shift in timing could be attributed to the altered schedules and leisurely activities that individuals typically engage in during weekends and holidays. People might be more inclined to initiate their evening commutes earlier to accommodate social plans, family gatherings, or recreational activities that are common during non-working days.

## **Exploratory Spatial Data Analysis**

Exploratory Spatial Data Analysis or ESDA consists of descriptive techniques to discover spatial distribution of data and identify outliers. In this ESDA section, I will cover global spatial autocorrelation which focuses on overall trend and local spatial autocorrelation which focuses on hot and cold spots in the data.

### **Global Spatial Autocorrelation**

In this section, I will include the computation of global spatial autocorrelation statistics and spatial complete randomness test for global spatial autocorrelation. The goal here is to understand whether the passenger trips generated by origin are evenly distributed across Singapore.

#### **Spatial Weights Matrix**

Before computing global spatial autocorrelation, we need to define spatial neighbourhood by using spatial weight. There are two common methods to compute spatial weight which are contiguity-based and distanced-based.

In contiguity-based method, neighbour share common boundary and there are 2 methods in defining the boundary, ROOK by common edge while QUEEN by common edge and vertices as shown below for square shape.

![Hook Neighbors](figure/Rook.png){width="241"}

![Queen Neighbors](figure/Queen.png)

In hexagonal grid, finding neighbours are straighforward. Both ROOK and QUEEN yield the same results as shown below.

![Hexagon Neighbors](figure/Hexagonal_Neighbors.png)

In distance-based method, there are 2 method fixed weighting where the grid are considered neighbours if they are within specified distance from one another and adaptive weighting where each grid has same specified number of neighbours.

If the hexagonal grid are isolated from each other, contiguity-based method may not be appropriate as it may yield many grids with no neighbours.

#### Contiguity Weight Matrix (QUEEN)

In the code chunk below, I will use [*`poly2nb()`*](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package to compute contiguity weight matrices for weekday morning peak hour. This function builds a list of neighbours based on grids with contiguous boundaries. By default, Queen contiguity is applied.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
wm_q <- poly2nb(total_trips_per_grid_wdmp, queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 1492 hexagonal grids. There are 12 hexagonal grid with no neighbour, 40 hexagonal grids with 1 neighbour and the most connected grids have 6 links. The average number of links is 4.5.

#### Contiguity Weight Matrix (ROOK)

In the code chunk below, I will use [*`poly2nb()`*](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package to compute contiguity weight matrices for weekday morning peak hour by specifying `queen = FALSE` to compute Rook contiguity.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
wm_r <- poly2nb(total_trips_per_grid_wdmp, queen=FALSE)
summary(wm_r)
```

The summary report above shows that there are 1492 hexagonal grids. There are 12 hexagonal grid with no neighbour, 40 hexagonal grids with 1 neighbour and the most connected grids have 6 links. The average number of links is 4.5.

Note: The results for both rook and queen method are the same as shown from the computation above.

#### Visualising contiguity weights

Before visualising the weights, I need to reproject coordingate to WGS84 for longitude-latitude projection using *`st_transform`* of **sf** package.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wdmp$area_honeycomb_grid <- st_transform(total_trips_per_grid_wdmp$area_honeycomb_grid, "+proj=longlat +datum=WGS84")
```

Next, I will get the coordinates of the hexagonal grid centroid in longitude and latitude using the *`st_coordinates`* and *`st_centroid`* of **sf** package.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
coords <- st_coordinates(st_centroid(total_trips_per_grid_wdmp$area_honeycomb_grid))
head(coords)
```

I will only plot queen contiguity as rook contiguity yields the same results.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
plot(total_trips_per_grid_wdmp$area_honeycomb_grid, border="lightgrey", main="Queen and Rook Contiguity")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
```

#### Fixed Distance Weight Matrix

*The [dnearneigh()](https://r-spatial.github.io/spdep/reference/dnearneigh.html)* of **spdep** package will be used to derive the distance-based weight matrices by . This function identifies neighbours of hexagonal grid centroid points by Euclidean distance with a lower and upper bounds distance controlled by the *bounds* argument or by Great Circle distance in kilometres if *longlat* argument is set to TRUE.

##### **Determine the cut-off distance**

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [*`knearneigh()`*](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep.**

-   Convert the knn object returned by *knearneigh()* into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [*`knn2nb()`*](https://r-spatial.github.io/spdep/reference/knn2nb.html).

-   Return the length of neighbour relationship edges by using [*`nbdists()`*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using [`unlist()`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
#| code-fold: true
#| code-summary: "Show the code"
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 4,582.5 metres, so using a number slightly larger than this (i.e. 4.6) as the upper threshold gives certainty that all regions will have at least one neighbour.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wdmp$grid_id[match(max(k1dists), k1dists)]
```

Using the code chunk above, we discover that the grid_id with the maximum distance to its nearest neighbour is 1767 which is the grid in Johor.

##### **Computing fixed distance weight matrix**

Now, we will compute the distance weight matrix by using [*dnearneigh()*](https://r-spatial.github.io/spdep/reference/dnearneigh.html) as shown below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
wm_d4.6 <- dnearneigh(coords, 0, 4.6, longlat = TRUE)
wm_d4.6
```

From the output, we see that the average number of links is 158.4651. The number is quite high and may skew the analysis.

Next, we will use *str()* to display the content of `wm_d4.6` weight matrix.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
str(wm_d4.6)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
par(mfrow = c(1,2))
plot(total_trips_per_grid_wdmp$area_honeycomb_grid, border = "lightgrey",main="1st nearest neighbours" )
plot(k1, coords, add = TRUE, col = "red", length = 0.88, )

plot(total_trips_per_grid_wdmp$area_honeycomb_grid, border = "lightgrey", main = "Distance Link")
plot(wm_d4.6, coords, add = TRUE, pch = 19, cex = 0.6)
```

Due to a high number of links, we have very dense graphs which make it difficult to interpret. However, we can still make some observations:

-   The above charts actually illustrates a characteristic of fixed distance weight matrix whereby the hexagonal grid of busttop origin in the centre of Singapore tend to have more neighbours and the edges of Singapore with lesser neighbours like Johor, Tanah Merah Coast.

-   Based on the above charts, we can tell that the geographical areas of the regions in Singapore are highly connected by the bus.

#### Adaptive Distance Weight Matrix

To overcome the issue of fixed distance weight matrix where there is uneven distribution of neighbours, we can use directly control the numbers of neighbours using k-nearest neighbours, as shown in the code chunk below.

I will set k = 6 i.e., all hexagonal grids will have 6 neighbours for hexagonal grids.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```

#### Plotting distance based neighbours

```{r}
#| code-fold: true
#| code-summary: "Show the code"
par(mfrow = c(1,2))
plot(total_trips_per_grid_wdmp$area_honeycomb_grid, border = "lightgrey",main="6 nearest neighbours" )
plot(knn6, coords, add = TRUE, col = "red", length = 0.88, )

plot(total_trips_per_grid_wdmp$area_honeycomb_grid, border = "lightgrey", main = "Distance Link w KNN")
plot(knn6, coords, add = TRUE, pch = 19, cex = 0.6)


```

#### Determining Which Weights Matrix to Use

Selecting a spatial weight matrix is use is dependent on the geographical area of interest and the focus of the study. Contiguity-based is preferred for hexagonal grid with uniform sizes because contiguity matrices are well-suited for regular grids where neighboring units share common boundaries. However, in my case, there are some hexagonal grid with no neighbour making contiguity-based not preferable. Therefore, I will use distance-based methods with adaptive distance spatial weight matrix because fixed distance has disadvantage where some regions only have 1 neighbour, while others may have 158 neighbours.

#### **Row-Standardised Weights Matrix**

After selecting the weight matrix to use, I will now assign weights to each neighboring polygon. Each neighboring polygon will be assigned equal weight (style="W") by assigning the fraction 1/(#of neighbors) to each neighbouring area. This is also known as a row-standardised matrix where each row in the matrix sums to 1.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
rswm_knn6 <- nb2listw(knn6,
                   style = "W",
                   zero.policy = TRUE)
rswm_knn6
```

I will be using the row-standardised weight matrix for the next part of the analysis.

Notes:

The input of *nb2listw()* must be an object of class **nb**. The syntax of the function has two major arguments, namely style and zero.poly.

-   *style* can take values "W", "B", "C", "U", "minmax" and "S". B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).

-   If *zero policy* is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

The above processes are previously implemented on Weekday Morning Peak Hour. Next, I will implemented the same process as above for Weekday Afternoon Peak Hour, Weekends/Holiday Morning Peak Hour and Weekends/Holiday Evening Peak Hour

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wdap$area_honeycomb_grid <- st_transform(total_trips_per_grid_wdap$area_honeycomb_grid, "+proj=longlat +datum=WGS84") 

coords_wdap <- st_coordinates(st_centroid(total_trips_per_grid_wdap$area_honeycomb_grid)) 
knn6_wdap <- knn2nb(knearneigh(coords_wdap, k=6)) 
rswm_knn6_wdap <- nb2listw(knn6_wdap,
                   style = "W",
                   zero.policy = TRUE)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wdap$area_honeycomb_grid <- st_transform(total_trips_per_grid_wdap$area_honeycomb_grid, "+proj=longlat +datum=WGS84")
coords_wdap <- st_coordinates(st_centroid(total_trips_per_grid_wdap$area_honeycomb_grid)) 
knn6_wdap <- knn2nb(knearneigh(coords_wdap, k=6)) 
rswm_knn6_wdap <- nb2listw(knn6_wdap,
                   style = "W",
                   zero.policy = TRUE)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wemp$area_honeycomb_grid <- st_transform(total_trips_per_grid_wemp$area_honeycomb_grid, "+proj=longlat +datum=WGS84")
coords_wemp <- st_coordinates(st_centroid(total_trips_per_grid_wemp$area_honeycomb_grid)) 
knn6_wemp <- knn2nb(knearneigh(coords_wemp, k=6)) 
rswm_knn6_wemp <- nb2listw(knn6_wemp,
                   style = "W",
                   zero.policy = TRUE)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_weep$area_honeycomb_grid <- st_transform(total_trips_per_grid_weep$area_honeycomb_grid, "+proj=longlat +datum=WGS84") 
coords_weep <- st_coordinates(st_centroid(total_trips_per_grid_weep$area_honeycomb_grid)) 
knn6_weep <- knn2nb(knearneigh(coords_weep, k=6)) 
rswm_knn6_weep <- nb2listw(knn6_weep,
                   style = "W",
                   zero.policy = TRUE)
```

#### **Computing Global Spatial Autocorrelation Statistics**

This in sub-section, I will use two methods: Moran's I and Geary's C to test the hypothesis the following hypothesis:

-   H0: Observed spatial patterns of values is equally likely as any other spatial pattern i.e. data is randomly disbursed, no spatial pattern

-   H1: Data is more spatially clustered than expected by chance alone.

**Moran's I**

I will perform Moran's I statistical testing by using [*`moran.test()`*](https://r-spatial.github.io/spdep/reference/moran.test.html) of **spdep pacakage**. Moran's I describe how features differ from the values in the study area as a whole. The Moran I statistic ranges from -1 to 1. If the Moran I is:

-   positive (I\>0): Clustered, observations tend to be similar

-   negative (I\<0): Disperse, observations tend to be dissimilar

-   approximately zero: observations arranged randomly over space

The below code chunk will perform the Moran's I test on the passenger trips generate by origin.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
moran.test(total_trips_per_grid_wdmp$total_trips,
           listw = rswm_knn6,
           zero.policy = TRUE,
           na.action = na.omit)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
moran.test(total_trips_per_grid_wdap$total_trips,
           listw = rswm_knn6_wdap,
           zero.policy = TRUE,
           na.action = na.omit)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
moran.test(total_trips_per_grid_wemp$total_trips,
           listw = rswm_knn6_wemp,
           zero.policy = TRUE,
           na.action = na.omit)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
moran.test(total_trips_per_grid_weep$total_trips,
           listw = rswm_knn6_weep,
           zero.policy = TRUE,
           na.action = na.omit)
```

Since the p-value \< 0.05, I have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone. Since Moran I statistics are larger than 0, the observation are clustered, observations tend to be similar.

**Computing Monte Carlo Moran's I**

If there are doubts that the assumptions of Moran's I are true (normality and randomisation), a Monte Carlo simulation is used to perform a permutation test for Moran's I.

The permutation tests consists of randomly reassigning the attribute values to a cell under the assumption of no spatial pattern. This random assignment is conducted n times. Each time, I will compute the Moran's I to crerate an empirical distribution of Moran's I under H0.

The code chunk below performs permutation test for Moran's I statistic by using [*`moran.mc()`*](https://r-spatial.github.io/spdep/reference/moran.mc.html) of **spdep** package with a total of 1000 simulation.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)
bperm= moran.mc(total_trips_per_grid_wdmp$total_trips, 
                listw=rswm_knn6, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)
bperm_wdap= moran.mc(total_trips_per_grid_wdap$total_trips, 
                listw=rswm_knn6_wdap, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm_wdap
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)
bperm_wemp= moran.mc(total_trips_per_grid_wemp$total_trips, 
                listw=rswm_knn6_wemp, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm_wemp
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)
bperm_weep= moran.mc(total_trips_per_grid_weep$total_trips, 
                listw=rswm_knn6_weep, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm_weep
```

Since the p-value is \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

**Geary's C**

Geary's C considers the difference between respective observations meaning that it describe how features differ from their immediate neighbours. Geary's C range from -1 to an undefined number above 1. If the Geary's C is:

-   Large (c\>1): Dispersed, observations tend to be dissimilar

-   Small (c\<1): Clustered, observations tend to be similar

-   c = 1: observations arranged randomly over space

The code chunk below performs Geary's C test for spatial autocorrelation for passenger trips generate by origin using [*`geary.test()`*](https://r-spatial.github.io/spdep/reference/geary.test.html) of **spdep** pacakage.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
geary.test(total_trips_per_grid_wdmp$total_trips, listw = rswm_knn6)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
geary.test(total_trips_per_grid_wdap$total_trips, listw = rswm_knn6_wdap)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
geary.test(total_trips_per_grid_wemp$total_trips, listw = rswm_knn6_wemp)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
geary.test(total_trips_per_grid_weep$total_trips, listw = rswm_knn6_weep)
```

For Weekday Morning Peak Hour, Weekends/Holiday Morning Peak and Weekends/Holiday Evening Peak, the p-value \< 0.05, there is sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone. The Geary C statistics are less than 1 suggesting that clusters are present . This finding is consistent with the results of the Global Moran's I test in the previous section.

However, for Weekday Afternoon Peak Hour, the p-value \> 0.05, suggesting that there is no sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This mean that the data is randomly disbursed with no spatial pattern which is not consistent with results of the Global Moran's I test in the previous section.

**Computing Monte Carlo Geary's C**

Similar to Moran's I, Monte Carlo simulation is used to perform a permutation test for Geary's C. The code chunk below performs permutation test for Geary's C statistic by using *`geary.mc()`* of **spdep** pacakagepackeage with a total of 1000 simulation.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)
bperm_func = geary.mc(total_trips_per_grid_wdmp$total_trips,
                 listw = rswm_knn6,
                 nsim = 999)
bperm_func
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)
bperm_func_wdap = geary.mc(total_trips_per_grid_wdap$total_trips,
                 listw = rswm_knn6_wdap,
                 nsim = 999)
bperm_func_wdap
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
bperm_func_wemp = geary.mc(total_trips_per_grid_wemp$total_trips,
                 listw = rswm_knn6_wemp,
                 nsim = 999)
bperm_func_wemp
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
bperm_func_weep = geary.mc(total_trips_per_grid_weep$total_trips,
                 listw = rswm_knn6_weep,
                 nsim = 999)
bperm_func_weep
```

For Weekday Morning Peak Hour, Weekends/Holiday Morning Peak and Weekends/Holiday Evening Peak, the p-value is less than 0.05, suggesting that there is sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

However, for Weekday Afternoon Peak Hour, the p-value \> 0.05, suggesting that there is no sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence, suggesting that the data is randomly disbursed with no spatial pattern.

## **Local Spatial Autocorrelation Statistics**

From the results above, I have established the statistical testing that spatial clustering occurs for Weekday Morning Peak Hour, Weekends/Holiday Morning Peak and Weekends/Holiday Evening but not for Weekday Afternoon Peak Hour in Singapore.

In this section, I will detect clusters/outliers and discover hot or cold spots using Local Spatial Autocorrelation Statistics with Local Indicators of Spatial Association (LISA).

### **Local Indicators of Spatial Association (LISA) Analysis**

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable.

In this section, I will apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran'I to detect cluster and/or outlier from passenger trips generate by origin at hexagon level.

Positive Local Moran\'s I value indicates that a feature has neighboring features with similarly high or low attribute values which refer to a cluster. While Negative Local Moran\'s I value indicates that a feature has neighboring features with dissimilar values which refer to an outlier.

**Computing local Moran's I**

I will use [*`localmoran()`*](https://r-spatial.github.io/spdep/reference/localmoran.html) function of **spdep** package to compute local Moran's I by first computing *Ii* values, given a set of *zi* values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

The code chunks below are used to compute local Moran's I of Total Trips at the hexagonal grid level.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
fips <- order(total_trips_per_grid_wdmp$grid_id)
localMI <- localmoran(total_trips_per_grid_wdmp$total_trips, rswm_knn6)
head(localMI)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
fips_wdap <- order(total_trips_per_grid_wdap$grid_id)
localMI_wdap <- localmoran(total_trips_per_grid_wdap$total_trips, rswm_knn6_wdap)
head(localMI_wdap)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
fips_wemp <- order(total_trips_per_grid_wemp$grid_id)
localMI_wemp <- localmoran(total_trips_per_grid_wemp$total_trips, rswm_knn6_wemp)
head(localMI_wemp)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
fips_weep <- order(total_trips_per_grid_weep$grid_id)
localMI_weep <- localmoran(total_trips_per_grid_weep$total_trips, rswm_knn6_weep)
head(localMI_weep)
```

*localmoran()* function returns a matrix of values whose columns are:

-   Ii: the local Moran's I statistics

-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviate of local moran statistic

-   Pr(): the p-value of local moran statistic

The code chunk below list the content of the local Moran matrix derived by using [*printCoefmat()*](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/printCoefmat). Since the matrix is very long, I only show the head().

```{r}
#| code-fold: true
#| code-summary: "Show the code"
printCoefmat(head(data.frame(
  localMI[fips,], 
  row.names=total_trips_per_grid_wdmp$grid_id[fips]),
  check.names=FALSE))
```

**Mapping Local Moran's I values and p-values**

Next, I will append the local Moran's I dataframe onto `nigeria` SpatialPolygonDataFrame in preparation for the next part. This can be done using the code chunks below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wdmp.localMI <- cbind(total_trips_per_grid_wdmp,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wdap.localMI_wdap <- cbind(total_trips_per_grid_wdap,localMI_wdap) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_wemp.localMI_wemp <- cbind(total_trips_per_grid_wemp,localMI_wemp) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
total_trips_per_grid_weep.localMI_weep <- cbind(total_trips_per_grid_weep,localMI_weep) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

Let's visualise both the Local Moran's I values and its p-values using the choropleth mapping functions of **tmap** package.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
localMI.map <- tm_shape(total_trips_per_grid_wdmp.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(total_trips_per_grid_wdmp.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
localMI_wdap.map <- tm_shape(total_trips_per_grid_wdap.localMI_wdap) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue_wdap.map <- tm_shape(total_trips_per_grid_wdap.localMI_wdap) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI_wdap.map, pvalue_wdap.map, asp=1, ncol=2)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
localMI_wemp.map <- tm_shape(total_trips_per_grid_wemp.localMI_wemp) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue_wemp.map <- tm_shape(total_trips_per_grid_wemp.localMI_wemp) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI_wemp.map, pvalue_wemp.map, asp=1, ncol=2)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
localMI_weep.map <- tm_shape(total_trips_per_grid_weep.localMI_weep) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue_weep.map <- tm_shape(total_trips_per_grid_weep.localMI_weep) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI_weep.map, pvalue_weep.map, asp=1, ncol=2)
```

I will further build a choropleth and shade only grids that are statistically significant using the chunk code below. Firstly, I create ane object that consist statistically significant values using filter(). Then, I plot the base map consisting of the polygons features and lastly I overlay the base map with the statically significant Moran I' value map. The processes are repeated for the other peah hour group.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#Wdmp
total_trips_per_grid_wdmp.localMI_sig_wdmp <- cbind(total_trips_per_grid_wdmp,
                                                 localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..) %>%
  filter(Pr.Ii < 0.05)

base_wdmp <- tm_shape(total_trips_per_grid_wdmp) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_sig_wdmp.map <- base_wdmp + 
  tm_shape(total_trips_per_grid_wdmp.localMI_sig_wdmp) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n(Weekday Morning Peak) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

#wdap
total_trips_per_grid_wdap.localMI_sig_wdap <- cbind(total_trips_per_grid_wdap,localMI_wdap) %>%
  rename(Pr.Ii = Pr.z....E.Ii..) %>%
  filter(Pr.Ii < 0.05)

base_wdap <- tm_shape(total_trips_per_grid_wdap) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_sig_wdap.map <- base_wdap + 
  tm_shape(total_trips_per_grid_wdap.localMI_sig_wdap) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n(Weekday Afternoon Peak) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

#wemp
total_trips_per_grid_wemp.localMI_sig_wemp <- cbind(total_trips_per_grid_wemp,localMI_wemp) %>%
  rename(Pr.Ii = Pr.z....E.Ii..) %>%
  filter(Pr.Ii < 0.05)

base_wemp <- tm_shape(total_trips_per_grid_wemp) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_sig_wemp.map <- base_wemp + 
  tm_shape(total_trips_per_grid_wemp.localMI_sig_wemp) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n(Weekends/Holiday Morning Peak) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

#weep
total_trips_per_grid_weep.localMI_sig_weep <- cbind(total_trips_per_grid_weep,localMI_weep) %>%
  rename(Pr.Ii = Pr.z....E.Ii..) %>%
  filter(Pr.Ii < 0.05)

base_weep <- tm_shape(total_trips_per_grid_weep) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_sig_weep.map <- base_weep + 
  tm_shape(total_trips_per_grid_weep.localMI_sig_weep) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n(Weekends/Holiday Afternoon Peak) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

tmap_arrange(localMI_sig_wdmp.map,localMI_sig_wdap.map, localMI_sig_wemp.map,localMI_sig_weep.map)
```

A positive Local Moran's I value indicates that a feature is part of a cluster while a negative Local Moran's I value indicates that a feature is an outlier. From the plot above, it it notable that north of Singapore which is around Woodlands are has 1 cluster with green shade for weekdays. While for weekends/holiday, there are more yellow referring to outliers except for the south part of Singapore, there is a noticeable cluster with green shade.

### Plotting LISA Cluster Map

The local Moran's I value alone is not enough to show spatial clustering because it does not tell us whether the value of the variable being tested is high or low and whether the test result was significant. Therefore, I will assign each observation to a quadrant depending on the value of the variable on the y-axis (centred around the mean) and Moran's I on the x-axis. Quadrant 1 contains coldspots and quadrant contains hotspot as follows:

![LISA_Quadrant](figure/Lisa_Quadrant.png)

LISA Cluster Maps also categorises each region into one of five groups: (1) High-High, (2) High-Low, (3) Low-High, (4) Low-Low and (5) Insignificant.

The following steps are conducted to prepare for LISA cluster map:

1.  Create a vector of the same length as the number of hexagonal grid in each peak hour datasets.

2.  Derive a variable, `DV` by using a by using the spatially lagged version of total_trips and center it around its means. When DV \> 0, the spatially lagged variable of the region is higher than the mean.

3.  Derive a variable, `L_MI` using the Local Moran's I.

4.  Set the significance level for the local Moran.

5.  Define the command lines for: high-high, low-low, low-high, high-low

6.  Place statistically insignificant Moran I in the category 0.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#Step 1
quadrant <- vector(mode = 'numeric', length = nrow(localMI))
#Step 2
total_trips_per_grid_wdmp$lag_total_trips <- lag.listw(rswm_knn6, total_trips_per_grid_wdmp$total_trips)
DV <- total_trips_per_grid_wdmp$lag_total_trips - mean(total_trips_per_grid_wdmp$lag_total_trips)     
#Step 3
LM_I <- localMI[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant[DV <0 & LM_I>0] <- 1 #low-low
quadrant[DV >0 & LM_I<0] <- 2 #high-low
quadrant[DV <0 & LM_I<0] <- 3 #low-high
quadrant[DV >0 & LM_I>0] <- 4 #high-high
#Step 6
quadrant[localMI[,5]>signif] <- 0 
```

The code chunk below is to plot the LISA cluster map for Weekday Morning Peak Hour.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#Assign each region  to its respective quadrant
total_trips_per_grid_wdmp.localMI$quadrant <- quadrant
#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_wdmp <- tm_shape(total_trips_per_grid_wdmp.localMI) + 
  tm_fill(col = "quadrant",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n Weekday Morning Peak Hour ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)
```

The above processes are implemented for the other peak hours group.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#Step 1
quadrant_wdap <- vector(mode = 'numeric', length = nrow(localMI_wdap))
#Step 2
total_trips_per_grid_wdap$lag_total_trips <- lag.listw(rswm_knn6_wdap, total_trips_per_grid_wdap$total_trips)
DV_wdap <- total_trips_per_grid_wdap$lag_total_trips - mean(total_trips_per_grid_wdap$lag_total_trips)     
#Step 3
LM_I_wdap <- localMI_wdap[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant_wdap[DV_wdap <0 & LM_I_wdap>0] <- 1 #low-low
quadrant_wdap[DV_wdap >0 & LM_I_wdap<0] <- 2 #high-low
quadrant_wdap[DV_wdap <0 & LM_I_wdap<0] <- 3 #low-high
quadrant_wdap[DV_wdap >0 & LM_I_wdap>0] <- 4 #high-high
#Step 6
quadrant_wdap[localMI_wdap[,5]>signif] <- 0 

#Assign each region  to its respective quadrant
total_trips_per_grid_wdap.localMI_wdap$quadrant_wdap <- quadrant_wdap
#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_wdap <- tm_shape(total_trips_per_grid_wdap.localMI_wdap) + 
  tm_fill(col = "quadrant_wdap",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant_wdap)))+1],
          labels = clusters[c(sort(unique(quadrant_wdap)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n Weekday Afternoon Peak Hour ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#Step 1
quadrant_wemp <- vector(mode = 'numeric', length = nrow(localMI_wemp))
#Step 2
total_trips_per_grid_wemp$lag_total_trips <- lag.listw(rswm_knn6_wemp, total_trips_per_grid_wemp$total_trips)
DV_wemp <- total_trips_per_grid_wemp$lag_total_trips - mean(total_trips_per_grid_wemp$lag_total_trips)     
#Step 3
LM_I_wemp <- localMI_wemp[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant_wemp[DV_wemp <0 & LM_I_wemp>0] <- 1 #low-low
quadrant_wemp[DV_wemp >0 & LM_I_wemp<0] <- 2 #high-low
quadrant_wemp[DV_wemp <0 & LM_I_wemp<0] <- 3 #low-high
quadrant_wemp[DV_wemp >0 & LM_I_wemp>0] <- 4 #high-high
#Step 6
quadrant_wemp[localMI_wemp[,5]>signif] <- 0 

#Assign each region  to its respective quadrant
total_trips_per_grid_wemp.localMI_wemp$quadrant_wemp <- quadrant_wemp
#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_wemp <- tm_shape(total_trips_per_grid_wemp.localMI_wemp) + 
  tm_fill(col = "quadrant_wemp",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant_wemp)))+1],
          labels = clusters[c(sort(unique(quadrant_wemp)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n Weekends/Holiday Morning Peak Hour ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#Step 1
quadrant_weep <- vector(mode = 'numeric', length = nrow(localMI_weep))
#Step 2
total_trips_per_grid_weep$lag_total_trips <- lag.listw(rswm_knn6_weep, total_trips_per_grid_weep$total_trips)
DV_weep <- total_trips_per_grid_weep$lag_total_trips - mean(total_trips_per_grid_weep$lag_total_trips)     
#Step 3
LM_I_weep <- localMI_weep[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant_weep[DV_weep <0 & LM_I_weep>0] <- 1 #low-low
quadrant_weep[DV_weep >0 & LM_I_weep<0] <- 2 #high-low
quadrant_weep[DV_weep <0 & LM_I_weep<0] <- 3 #low-high
quadrant_weep[DV_weep >0 & LM_I_weep>0] <- 4 #high-high
#Step 6
quadrant_weep[localMI_weep[,5]>signif] <- 0 

#Assign each region  to its respective quadrant
total_trips_per_grid_weep.localMI_weep$quadrant_weep <- quadrant_weep
#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_weep <- tm_shape(total_trips_per_grid_weep.localMI_weep) + 
  tm_fill(col = "quadrant_weep",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant_weep)))+1],
          labels = clusters[c(sort(unique(quadrant_weep)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n Weekends/Holiday Evening Peak Hour ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)
```

Next, I will plot the local Moran's I map (statistically significant values only) and LISA map together. The shaded hexagonal grids will be the same for each pair of maps.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_arrange(localMI_sig_wdmp.map, LISAmap_wdmp,
  localMI_sig_wdap.map, LISAmap_wdap,
  ncol =2)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_arrange(localMI_sig_wemp.map, LISAmap_wemp,
  localMI_sig_weep.map, LISAmap_weep,
  ncol =2)
```

The LISA maps provides extra information whether the hexagonal grids have relatively higher or lower passenger trips generate by origin. Overall, Local Moran's have revealed significant spatial cluster and outliers.

From the results above, it is noticed that there are only 3 type of quadrants which are insignificant, low-high and high-high. For ease of interpreting the result, below are the maps of Singapore regions.

![Singapore Regions](figure/Singapore%20Regions.png)

**Weekday Morning Peak Hour:**

From the Local Moran's I map, there are some hexagonal grids with positive Local Moran's I values and they have neigbours with another high or low passenger trip grids. This consistent with the LISA maps. The high-high clusters spread across Singapore while the low-high outliers are typically near the high-high clusters. The hexagonal grid near the Singapore Malaysia border (Johor and edges near the border) are high-high cluster indicating a high level of cross country activities during the weekday morning.

**Weekday Afternoon Peak Hour:**

The cluster with high-high characteristics are distributed throughout Singapore with exception of West Singapore where only low-high outliers are apparent. This is attributed to the presence of Boon Lay Bus Interchange as the sole busy interchange in the western region, leading to comparatively lower passenger trips in the other parts of West Singapore.

**Weekends/Holiday Morning Peak Hour:**

The cluster with high-high characteristics are distributed throughout Singapore especially in the CBD/Central area where a significant concentration of passenger trips are observed during these times. This elevated activities may be influenced by various factors such as recreational activities, family/friend gathering, etc., contributing to the high level of engagement and movement in the CBD area.

**Weekends/Holiday Evening Peak Hour:**

The distribution of high-high cluster and low-high outliers are quite similar with Weekends/Holiday Morning Peak Hour except that the high-high cluster are wider around the CBD area during evening and there is no high-high cluster around the Yishun area as compared to weekends/holiday morning peak hour.

## Conclusion

In this take-home exercise, ESDA was used to generate insights about the distribution of passenger trips in Singapore. Using the Global Spatial Autocorrelation Statistics, it is noted that there is existence of spatial autocorrelation for all peak hour groups as whole analysis using Moran's I statistical test. However, when employing Geary's C, which accounts for differences with immediate neighbors, the data on weekday afternoon peak hour passenger trips is determined to be randomly dispersed, showing no discernible spatial pattern.

The existence of spatial autocorrelation led me to use local spatial autocorrelation statistics like LISA cluster maps to identify areas of clusters and outliers. Understanding the uneven distribution of passenger trips for different peak hours will be crucial for optimizing public transportation infrastrcuture, managing congestion and enhancing overall urban mobility.

In conclusion, the insights gained from both global and local spatial autocorrelation analyses contribute to a comprehensive understanding of passenger trip patterns for targeted interventions and strategic planning which in turn help to improve the efficiency and sustainability of transportation systems in Singapore. To enhance the depth of transportation dynamics analysis, future work could explore destination-specific or individual bus route considerations.

## References

\[1\] <https://urbandatapalette.com/post/2021-08-tessellation-sf/>
